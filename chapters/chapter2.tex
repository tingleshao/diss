\chapter{Microscopy}

This paper introduces an analysis-aware microscopy video compression method designed for microscopy videos that are consumed by analysis algorithms rather than by the human visual system. We define the quality of a microscopy video based on the level of preservation of analysis results. We evaluated our method with a bead tracking analysis program. For the same error level in the analysis result, our method can achieve 100x compression on certain test microscopy videos while maintaining @todo. Compared with a previous technique that yields exactly the same results by analysis algorithms, our method gives @todo more flexibility for a user to control the quality.  A modification to the new method also provides @todo.
Index Terms—biomedical image processing, data compression, image analysis

INTRODUCTION
The emergence of high-resolution, high-throughput microscopy systems is driving explosive growth in the size of video data produced by scientific experiments. One example of high-resolution microscopy system is described in [2]. However, growth in storage capacity and data transmission is not keeping up. As a consequence, video data is being compressed before transmission and storage.
Various video compression techniques have been invented and standardized in the past decades. Currently, several of the most widely used techniques are H.264, H265 and VP9 [13, 14, 19]. Each of these video compression techniques is designed to achieve acceptable compression performance on a wide range of videos while maintaining good visual quality for human observers, sometimes based on popular video quality metrics designed to measure this such as Peak Signal to Noise Ratio (PSNR).
A method for compressing single confocal fluorescence microscopy images is presented in [15]. In their work, they estimated signal to noise ratio (SNR) in microscopy images with the techniques described in [16][17]. The compression was achieved by spatial downsampling, intensity downsampling, and wavelet compression.
The idea of evaluating the quality of a video based on analysis algorithms can be found in [12]. In their paper, the video analysis routine is a set of computer vision algorithms: face recognition, face detection, and face tracking. They used H.264 to compress video multiple times with various quality settings to generate a set of the compressed video. They discovered that face recognition and face detection results are not sensitive to compression until they reach a particularly low quality setting. Above that, compression maintains similar face recognition and detection results as the original video. Experiments have also been performed on tracking faces in a set of compressed videos with a certain portion of frames dropped. They proposed that mutual information and blackness be two computed values that better correlate to the qualities of these analysis results that they can be considered as metrics.
These metrics differ from those required by scientific analysis algorithms [12]. An analysis algorithm may require extremely high-level preservation of details in a certain region of the video, far exceeding the sensitivity of the human visual system. On the other hand, certain parts of the video that are not relevant to the analysis may be completely ignored by the algorithm but may contain noise and irrelevant moving features that greatly reduce compressibility. This mismatch has lead us to design new video compression methods for microscopy videos that we call “analysis-aware microscopy video compression.”
Our efficient analysis-aware microscopy video compression method aims to provide the following features: a) in data reduction and encoding, the method should preserve the information in a microscopy video that is critical to analysis; b) it should reduce information in regions not relevant to the analysis; and c) it should be able to avoid compression and reconstruction artifacts that change the outcome of analysis even in ways that would improve results compared to the original video – analysis preformed on the compressed video should be indistinguishable from that performed on the original.
Our earlier work described a correlation-based compression method [1] that retained identical analysis results after compression. In this technique, a correlation-based threshold is used to detect the critical information (foreground) in a video. The foreground is then refined using mathematical morphology and losslessly stored in the compressed video. The remaining part is compressed by storing the temporal mean of that pixel location. We evaluated our methods using Video Spot Tracker [18] to track moving beads, which showed that our method can get at most 100x compression without any change to analysis results.  In comparison, H.264 compression either yielded much smaller compression ratio (lossless) or changed the analysis results (lossy).
In this paper, we extend this method to enable further increase in compressibility while still maintaining results that are statistically indistinguishable from samples of the original video. We observe that microscopy video analysis results are already altered by noise introduced in all stages of the microscopy video acquisition pipeline. The new method does not force the compressed video to have identical analysis result as the original video. Instead, it maintains the original information and replicates noise such that the error introduced by compression is statistically indistinguishable from that introduced by existing noise. This is verified by run multiple different statistical analyses on the original and compressed videos. For the case of analysis of bead-tracking results, this enables a reduction in the number of foreground pixels compared to the prior method, which enables even larger compression ratios without detectable changes in analysis.
The video compression method described in this paper and in our earlier work can be characterized as Region-of-Interest (ROI) based methods.  Previous ROI video encoding methods have been explored in [4][5][6]. One application of ROI video coding to face detection and tracking is discussed in [7]. Application to aerial videos is introduced in [8]. Chao et al. discussed the ROI video coding for preserving computer vision visual features in [9][10][11]. To our knowledge, there is no work done in exploring the use of ROI video coding for microscopy video analysis.
Section 2 describes our analysis-aware compression technique. Section 3 explains the quality measurement being used. Section 4 describes the experiments and discusses the result.  Section 5 concludes and talks about future work.
METHODS
The goal of our analysis aware microscopy video compression method is to have the compressed video retain all the information required for analysis. To achieve this, the pixels that contain the useful information need to be detected in every video frame.
The basic analysis-aware compression process is illustrated in Fig. 1. The basic form of our new method and our previous method both apply a two-step approach. a) In the first (segmentation) stage, the analysis-critical regions in every frame in the video are detected. The methods both use an approach based on correlation and mathematical morphology to determine the important part of the video in a domain- and analysis-independent manner. Every pixel in every frame is labeled as either foreground or background. This result is stored in a binary map. b) After the segmentation stage, the binary map is sent to a compression routine. The compression integrates the segmentation result in its encoding process so that for encoding setting the given fixed resource is allocated in a way to ensure that information in the analysis-critical region is well preserved. For this stage of the new algorithm, we designed and evaluated two different variations. They are detailed in Section 2.2.  After the compression is completed, the resulting compressed video has a much smaller size, and it is still useful for analysis. The extended form of our new algorithm includes a third stage: c) The compression may still introduce changes into the analysis result. To address this problem, we designed a post-processing stage to refine the compressed video. The post-processing stage makes use of the noise statistics in the video and refines the video by reproducing the noise that matches the video system characteristics as explained in Section 2.3.
Segmentation Stage
The goal of segmentation is to accurately detect the regions of pixels in a microscopy video frame that might affect analysis.  The analysis-independent method for this task made use of the point-spread function to remove regions containing only noise as described in our previous work [1] and detailed below. That used correlation followed by the mathematical morphology “open” operation (erosion followed by dilation) to clean up small false positives and then additional dilation to expand foreground region to expand the correlation-based segmentation result. This increased dilation (shown in figure 2) provided a conservative estimation of foreground regions to provide an (analysis-method-dependent) region increase to ensure identical results.  In the new method, the expanded region is not required, so the additional dilation is not performed – resulting in a much smaller foreground region and greater compression.
The correlation-based segmentation for detecting moving objects in microscopy video is the same in both the earlier and new method. It makes use of the effect Point Spread Function (PSF) on an image. Because of the PSF, every pixel is blended slightly with its neighboring pixels.  This means that any moving image feature will have a correlated impact on a region of pixels rather than only a single pixel. This does not hold for shot noise and electronic noise, which scale with image brightness but are uncorrelated between pixels. To get a foreground score for every pixel, we compute the Pearson’s correlation score between it and its neighbors:
 |    [Eq. 1]
In the formula, xj is the pixel intensity value for the center pixel at the jth frame,  is the mean pixel intensity value of the center pixel over a time interval, yij is the pixel intensity value for the neighbor pixel at jth frame, and  is the mean for the neighbor.
We compute this value for all eight neighboring pixels for each pixel. We then compute the maximum of all neighbor scores and use a threshold on this to determine which pixels are in the foreground. The threshold was determined in our earlier study by running multiple passes of bead tracking on the compressed video has the same tracking result as the uncompressed video but it can also be determined for a system with known sensor characteristics based on a likelihood threshold based on the system’s noise characteristics. Once determined, this threshold can be transferred to videos taken with similar experiment setups. After every pixel has a score assigned to it, all pixels whose score are above the threshold and are marked as potential foreground pixels in a binary map. This threshold is set to a liberal value to avoid losing actual features, with the result that the map contains many small false-positive pixel groups whose size is smaller than the PSF for a given microscope. The PSF would spread actual features over larger areas, so we remove these false positives using the mathematical erosion “open” operation. Fig. 2 shows one example of the test video frame image and the result binary map cleaned up by erosion. The resulting cleaned binary map guides compression.
Compression Stage

For the compression stage, the goal is to make use of the segmentation result to encode the video data so that information in the analysis-critical regions is preserved in a manner that does not affect analysis. There are many options for applying existing well-developed video codecs and integrating the analysis-critical map signals to compress the video data. In developing our system, we explored two paths. The first approach (used both in the earlier work and the new method) processes the video frames by averaging background pixel values over time and then losslessly compressing the processed video frames using a standard algorithm. The pre-processed video has many pixel locations with constant value over time, which can be efficiently encoded to provide high compression. Tests were done to compare four standard compression techniques and software: bzip2, jpeg2000, H.264 and H.265. The result showed that the three modern compression routines all give a similar good compression with our processed video frames. From these four methods, H.265 and H.264 achieve the smallest two compressed video file size based on our data set. H.265 is 4% smaller compressed video size than H.264 but the encoding speed of H.265 was much slower than other three techniques. Therefore we choose to use H.264 in our algorithm implementations and experiments. The results should apply to any lossless video compressor.
In an extension of the new method, we also evaluated replacing the background averaging with an approach that uses a combination of lossless and lossy compression. This approach works for block-based prediction-residual compression approaches. Our implementation used H.264. In H.264, the motion estimation unit is based on 16x16 pixel patch “macroblock”. The pixel data for each macroblock is transformed into the frequency domain. Data reduction is achieved by reducing the information in the high-frequency components in every macroblock. Specifically, information reduction is done by quantization that collapses a range of close values into one. Quantization level is mostly based on the given bandwidth in compression and it is generally a global property across blocks. But in our compression, we don’t need high quality for blocks that represent background pixels. Therefore our approach assigns different quantization levels to each block based on the segmentation result. We denote qp as the controlled value in quantization. A higher qp results in a wider range of values to be suppressed into one value, which results in shorter encoded bit length and lower video quality. As shown in Fig. 3, if in one block there are one or more pixels that are classified as foreground in the binary map, we use a better setting (qp=0); otherwise, we assign a worse setting (qp=51) to the block. This removes the need to calculate running averages across frames at the expense of variable-quantization encoding.
We also studied combining the two approaches: averaging the backgrounds and using customized qp assignment in compression. However, the combination yielded larger compressed video sizes than either technique applied by itself. This may be because the artificial edges introduced by the first stage are not usually well aligned with the macroblock boundaries, or it is not well aligned with the prediction model inside H.264.
Post-Processing Stage
By averaging the background pixels over time (V1), the compression is filtering out noise in the original video signal, producing an output video that has less noise than the input video.  This modifies the results of analysis routines whose kernels reach beyond the foreground pixels, such as the symmetry-based tracking kernels uses in our analysis.  This can produce more accurate tracking on the compressed video than the original.  While more accurate tracking could be considered better, it is also statistically different from the results of tracking in uncompressed video.  For cases where different regions of the video have different background fractions this can also produce track-to-track variations in the results.  Especially for analysis that looks at random motion distributions (like the mean-squared displacement calculations performed by our collaborators), this means that analysis on compressed video is different from analysis on uncompressed video.  In these cases, the loss of noise in the reconstructed video is a problem.
There are two ways to address this problem. The original method expanding the foreground regions based on knowledge about the spatial extent of the analysis kernels [1]. The new approach estimates the distribution of background noise in the original video and adds synthesized noise into the compressed video during decompression/analysis.  This has the benefit of being independent of the radius of the kernels for analysis performed on the video. This process is the post-processing stage of our method. During analysis, noise is generated and added back into the video in an on-line fashion. To avoid a per-pixel storage cost, the known characteristics of noise in optical microscopy systems can be used to model the entire image with only two parameters.
       [Eq. 2]
In estimating the noise parameters, we model noise value probability distribution as a Poisson + Gaussian distribution described in Eq. 2. By assuming a large sample size one can further simplify the distribution (speeding reconstruction calculations) into a single Gaussian distribution with non-zero mean. The only parameters are the mean and variance of the distribution. To obtain the parameters for the two distributions (signal and noise), we used k-means clustering method. By finding the two clusters of the pixel intensity over time points in the mean and variances space, we use the cluster with lower mean and variance and use its center as the mean-variance of the noise distribution. One sample plot of the pixel intensity over time’s mean vs. variance plot is shown in Fig. 4 where point A is the chosen cluster center.
Because standard video quality metrics such as PSNR and SSIM do not correlate well with analysis such as object tracking [12]. We seek a better metric for evaluation. In [1], the quality of the video was determined by running the same tracking analysis on the video, and only the video with output exactly matching the original video’s analysis result passed the validation. For our new work, we consider the fact that analysis results on the original video are affected by noise captured as part of the original video. Therefore they represent only one of a set of possible analysis results, and re-taking new uncompressed video of the same specimen would produce slightly different results. Therefore, the compressed video’s analysis does not have to exactly match that on that particular video, but it should be drawn from a distribution that matches those from multiple runs on the same specimen. We propose robust statistically-based video quality measurements based on the values derived from sets of analysis results.
This statistical approach can be used with any analysis. We demonstrate it using mean square displacement (MSD) curves that are derived from bead tracking results. An MSD value is calculated by averaging the squared displacement over movement measured using a fixed time window (τ).  A sequence of MSD values with increasing time windows contains information about the type of cell motion. By characterizing at the shape of the MSD vs. τ curve, characteristics of the specimen (diffusion coefficient, membrane stiffness) can be classified [3].
In our experiment, we converted the tracking trajectory result into a sequence of MSD values with different time windows. The quality of the video is determined based on the result of the quantitative tests on these MSD values compared to the MSD values from tracking in the original uncompressed video. We would like to verify that the error introduced by the compression matches that introduced by existing noise such that the two set of measurements are statistically indistinguishable.
Quantitative Tests
Because we judge the quality of a compressed video by comparing its error with that introduced by noise in the original video, the relative distributions should be considered. To provide confidence values, a quantitative approach in preferred. In testing the performance of our methods, we applied two experiments: the two-sample Kolmogorov-Smirnov (KS) test and Kullback-Leibler (K-L) divergence computation. We also plot the MSD mean values across a set of similar videos scaled as multiple of the MSD value for the original video for different compression methods.@todo: taylorr: what does this mean?
A) KS test
In our experiment, the goal is to show that the population of MSD samples from the compressed video group is not different from the population of the samples from the uncompressed video group. This can be verified using the KS test, which is a well-known technique for testing and giving the confidence level that two groups of values drawn from two continuous random distributions are actually drawn from the same distribution. Unlike the t-test, which mainly tests the difference be two populations’ means, the KS test takes the shape of the distribution into account and finds the largest vertical distance between two kernel density plots.
B) K-L divergence
Computing a K-L divergence can also compare two samples of MSD values from two unknown distributions. K-L divergence is a concept in information theory that measures the difference between two probability distributions. It can be understood as the information lost when probability distributions Q is used to approximated probability distribution P. In our experiment, P is the sampled population of the MSD values for the original video and Q is the sampled population of the MSD values for a compressed video. The measurement is non-symmetric: KL-div(P, Q) is generally different from KL-div(Q, P).
RESULTS
We performed two types of experiments to evaluate our new methods. The goal is to compare the new statistically-indistinguishable analysis-aware video compression method against the standard video compression technique H.264. We included both variations of the analysis-aware video compression method (V1 from [1] and V2 from this paper, using per-pixel temporal averaging) in the comparisons, and performed the comparisons for each with and without the noise-addition post-processing. Both synthetic microscopy video data and real microscopy video data are used in the experiments.
For each compression technique, we compare the performance of different compression methods under different bandwidth settings (compression ratios). We ran the tests with various configurations to generate different compressed video sizes. We then plotted the video quality evaluation results versus video data sizes. The experiments on synthetic data and real data are discussed separately in the next two subsections.
Experiment on Synthetic Data
The overall experiment flow on synthetic data is illustrated in Fig. 5. We wrote a program to generate synthetic microscopy video frames. This data generating process is composed of several stages. First, we use a program to simulate bead trajectories with Gaussian random walks. In this experiment, we generated 10 bead trajectories. The data was stored as a list of x-y pairs, describing the sub-pixel bead positions on every frame in the video. For an 1800-frame video with 10 beads, we had 10 lists with length 1800. With the bead trajectory data, we generated 10 videos that contain beads. All ten videos share the same bead trajectories.
In the second stage, for each bead position in every frame, we generate a 2D Gaussian blob with pre-determined mean intensity and standard deviation values. We place it so that it is centered at the given sub-pixel x-y location based on the trajectory data list. The result is a “clean” video without background noise.
The next step is to add per-pixel noise into the video using Eq. 2. We generated the final pixel intensity values with one Gaussian plus Poisson distribution with λ equals to the pixel intensity value and σ equals to 0.01. The values are selected such at the resulting video has the similar characteristic as a real microscopy video. Therefore in every video, the background and foreground pixels values differ, but they are samples from the same distribution.
This results in a set of 10 noisy videos. They each share the same bead trajectory, but they have different noise. Every video contains 10 beads. Every video has 1800 frames. Fig. 6 (a) shows 1 frame in one of the 10 videos.
We tested the compression methods with the noisy videos from the data generation process. For every video, we first identify the foreground using correlation-based segmentation followed by mathematical morphology. The dilation operator size in the refinement is set to 5 pixels, which is smaller than the value we used in our previous analysis-preserving compression work. This setting does not ensure the exact same analysis results as the original video. We generate a binary map from the first step. Then we process the video with five approaches to generate 5 sets of compressed videos: (a) based on the binary map, we average the background in the video and leave the foreground unchanged. Then we compress the video using H.264. (b) Based on the binary map, we apply a customized H.264 compression by applying a low quality setting (qp=51) for the background pixel blocks, and applying a high quality setting (lower qp) for the foreground pixel blocks. (c) We further add synthesized noise into the resulting compressed video from (a). (d) We further add synthesized noise into the resulting compressed video from (b). In method (e) we directly compress the original video (ignoring the binary map) using H.264.
To compare the performance of the five compression methods at different quality levels, we adjust the parameters to generate a set of compressed videos with different sizes for each compression method. In methods (a) and (c) we increase the dilation operator size from 5 pixels to a larger value, which produces a larger foreground region (and thus less compression). In methods (b) and (d) we used a list of qp values when compressing the foreground blocks in H.264 compression. In method (e) we used a list of qp values for H.264 compression so that we have different sized videos.  We call methods (a) and (c) analysis-aware compression variation 1 (V1).  We call (b) and (d) analysis-aware compression variation 2 (V2).
By including analysis-aware compression variation 1 in the experiment, we also include a generalization of the method described in [1]. By increasing morphology dilation size in the refinement stage described in [1], we eventually reach a large enough dilation size that makes the analysis result the same as the one for original video.
We plot the sizes of compressed videos from various compression methods so that we can compare their relative effectiveness at a given compressed size. For each method, we ran the compression with all 10 videos to generate a population of compressed videos. The compressed video size for the videos after post-processing is considered the same as before post processing because the post processing can be performed during reconstruction using the compressed video before post-processing as input.
We analyzed the tracking of beads using video spot tracker [18]. We applied the tracking on the original uncompressed video and all compressed videos: before post processing (a and b) and after post-processing (c and d).  We then computed the MSD for the tracking results. Fig. 7 shows the relationship between MSD values and video compression ratios. The MSD values were plotted as a multiple of the MSD values for original video (1.0 means the MSD values are identical to the ones from original videos). Each curve represents the mean MSD values among 10 copies of videos with the same foreground and different instances of sampled noise values from the same noise distribution.
The result suggests that two variations of our compression method both generate a higher quality compressed video because the points on the curves are all close to one (in the range between 0.98 and 1.02) whereas standard H.264 yields a curve far away from 1.0 given the same compression ratio. The curves for the videos after post-processing are closer to the 1.0 horizontal curve, indicating that post-processing of adding back-noise improves the video quality regarding analysis. V2 with post-processing is very close to the original result, indicating that it may be indistinguishable from it.
KS test
To further probe for potential differences between the original and compressed analysis, we performed the KS test on the MSD values. In this experiment, the MSD values were not normalized by the MSD values from the original videos. We used one bead’s MSD values across 10 versions of the videos that share the same foreground content. After that, we selected a fixed window size. Fig. 8 (a) shows the p values output from KS test for MSD values on videos compressed using our compression approach variation 1, our compression approach variation 2, and the standard H.264 compression. The curves plot p value vs. compression ratio. The horizontal line indicates the test decision threshold. For all p values above the line, the null hypothesis is not rejected, which means that there is no strong evidence that the MSD values obtained from compressed videos are sampled from a different population than those from the MSD values obtained from the original video (that is to say that they are statistically indistinguishable).
The KS test for standard H.264 compressed videos always rejects the null hypothesis, indicating that the distributions are statistically distinguishable. For our approach before the post-processing the curve sometimes goes above the threshold, but it also falls below the threshold as compression ratio increases. For the video compressed with our approach after post-processing, the curves are always above the threshold until it reaches a very high compression ratio.
K-L divergence
We also computed K-L divergence values on the same data.  The result is shown in Fig. 8 (b). A lower K-L divergence value suggests a smaller distance between the compressed video’s MSD value population and the original video MSD value population.
In this experiment, all compression videos with our methods gave similar results for compression ratios smaller than 148 (near 5 on the log scale horizontal axis), which was better than the result value from standard H.264. Our compression approach variation 2 outperformed standard H.264 up until a compression ratio of @todo.
Experiment on Real Data
We also performed experiments on videos from real experiments. For real data, it is impossible to get the true bead trajectory and generate multiple copies of the same bead trajectory and difference background noise. We handled this by dividing 1 video into 10 parts and perform tracking on each of them to produce a population of estimates. It is assumed that there is no significant background noise property change across the videos in single-video the test set. The experiment process is illustrated in Fig. 9.
The scaled MSD values for various compression methods vs. video compression ratio plot for real video data is given in Fig. 10. For real data, our compression approach variation 1 does not perform better than H.264 compression for compression ratios greater than about 200 (5.3 on the log scale horizontal axis), even after post-processing. On the other hand, compression approach variation 2 always gives a better result than H.264 compression.
Fig. 11 shows the MSD values from multiple compression methods compared using KS test p-value and K-L divergence value. For this data set, K-L divergence does not show a great difference among different compression methods. In the KS test, the p values for the videos compressed by standard H.264 start to drop below the threshold after it reaches a high compression ratio, while our compression method variation 2 remains above the threshold under the same compression ratio. Our compression method variation 1 cannot generate small enough video that reaches that large compression ratio.
CONCLUSION
We introduce a compression method that preserves analysis-critical information in microscopy video even at high compression ratios. The method compresses non-critical regions at relative low quality to yield a better compression ratio than standard compression does. We show that the method preserves scientific analysis by running statistical tests on it; the resulting probability distribution of analysis results is not statistically distinguishable from the analysis result probability distribution from the original video.
We performed video quality evaluation based on MSD values from tracking diffusing beads. The experiment result suggested that comparing against standard video compression technique H.264, for most compression ratio values, our method gives a better quality video in terms of the analysis results.
The method extends to other types of microscopy video analysis besides object tracking. The statistical validation method can be modified to apply to each type of analysis. We evaluated quality based on KS test and K-L divergence. If a different metric is desired, the statistical tests can be replaced with the new technique applied to the same population of data.
The correlation-based segmentation method used in our compression technique was verified by analysis of tracking in a fluorescence microscopy videos in our experiment. But in [1], we showed that this segmentation method works for a variety of microscopy video types including fluorescence video, bright field video, fast moving beads video and cell video and associated analysis routines including segmentation.
